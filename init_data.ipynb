{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUsed for ploting csv data\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Used for ploting csv data\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import time\n",
    "import pandas as pd\n",
    "import base_strategy as bs\n",
    "import init_data_helper as idh\n",
    "from fractions import Fraction as frac\n",
    "from tests.test_all_tests import get_test_data_path\n",
    "\n",
    "from binance import AsyncClient, Client\n",
    "import api_data as api # for Binance data\n",
    "from Historic_Crypto import HistoricalData # for CoinBase Pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in csv's\n",
    "list_of_csv = [\n",
    "    # TODO: figure out problems with 2017 data\n",
    "    # 'full_data__6__2017.csv', # don't use 2017 data, its not great\n",
    "    # 'full_data__6__2018.csv',\n",
    "    # 'full_data__6__2019.csv',\n",
    "    # 'full_data__6__2020.csv',\n",
    "    # 'full_data__6__2021.csv'\n",
    "]\n",
    "sorted_list_of_csv = [\n",
    "    # 'sorted_full_data_2017.csv',\n",
    "    'sorted_full_data_2018.csv',\n",
    "    'sorted_full_data_2019.csv',\n",
    "    'sorted_full_data_2020.csv',\n",
    "    'sorted_full_data_2021.csv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provisional Start: 2018-01-01T00:00:00\n",
      "Provisional End: 2018-01-01T05:00:00\n",
      "Provisional Start: 2018-01-01T05:00:00\n",
      "Provisional End: 2018-01-01T10:00:00\n",
      "Provisional Start: 2018-01-01T10:00:00\n",
      "Provisional End: 2018-01-01T15:00:00\n",
      "Provisional Start: 2018-01-01T15:00:00\n",
      "Provisional End: 2018-01-01T20:00:00\n",
      "Provisional Start: 2018-01-01T20:00:00\n",
      "Provisional End: 2018-01-02T01:00:00\n",
      "Provisional Start: 2018-01-02T01:00:00\n",
      "Provisional End: 2018-01-02T06:00:00\n",
      "Provisional Start: 2018-01-02T06:00:00\n",
      "Provisional End: 2018-01-02T11:00:00\n",
      "Provisional Start: 2018-01-02T11:00:00\n",
      "Provisional End: 2018-01-02T16:00:00\n",
      "Provisional Start: 2018-01-02T16:00:00\n",
      "Provisional End: 2018-01-02T21:00:00\n",
      "Provisional Start: 2018-01-02T21:00:00\n",
      "Provisional End: 2018-01-03T02:00:00\n",
      "Provisional Start: 2018-01-03T02:00:00\n",
      "Provisional End: 2018-01-03T07:00:00\n",
      "Provisional Start: 2018-01-03T07:00:00\n",
      "Provisional End: 2018-01-03T12:00:00\n",
      "Provisional Start: 2018-01-03T12:00:00\n",
      "Provisional End: 2018-01-03T17:00:00\n",
      "Provisional Start: 2018-01-03T17:00:00\n",
      "Provisional End: 2018-01-03T22:00:00\n",
      "Provisional Start: 2018-01-03T22:00:00\n",
      "Provisional End: 2018-01-04T03:00:00\n",
      "Provisional Start: 2018-01-04T03:00:00\n",
      "Provisional End: 2018-01-04T08:00:00\n",
      "Provisional Start: 2018-01-04T08:00:00\n",
      "Provisional End: 2018-01-04T13:00:00\n",
      "Provisional Start: 2018-01-04T13:00:00\n",
      "Provisional End: 2018-01-04T18:00:00\n",
      "Provisional Start: 2018-01-04T18:00:00\n",
      "Provisional End: 2018-01-04T23:00:00\n",
      "Provisional Start: 2018-01-04T23:00:00\n",
      "Provisional End: 2018-01-05T04:00:00\n",
      "Provisional Start: 2018-01-05T04:00:00\n",
      "Provisional End: 2018-01-05T09:00:00\n",
      "Provisional Start: 2018-01-05T09:00:00\n",
      "Provisional End: 2018-01-05T14:00:00\n",
      "Provisional Start: 2018-01-05T14:00:00\n",
      "Provisional End: 2018-01-05T19:00:00\n",
      "Provisional Start: 2018-01-05T19:00:00\n",
      "Provisional End: 2018-01-06T00:00:00\n",
      "Provisional Start: 2018-01-06T00:00:00\n",
      "Provisional End: 2018-01-06T05:00:00\n",
      "Provisional Start: 2018-01-06T05:00:00\n",
      "Provisional End: 2018-01-06T10:00:00\n",
      "Provisional Start: 2018-01-06T10:00:00\n",
      "Provisional End: 2018-01-06T15:00:00\n",
      "Provisional Start: 2018-01-06T15:00:00\n",
      "Provisional End: 2018-01-06T20:00:00\n",
      "Provisional Start: 2018-01-06T20:00:00\n",
      "Provisional End: 2018-01-07T01:00:00\n",
      "Provisional Start: 2018-01-07T01:00:00\n",
      "Provisional End: 2018-01-07T06:00:00\n",
      "Provisional Start: 2018-01-07T06:00:00\n",
      "Provisional End: 2018-01-07T11:00:00\n",
      "Provisional Start: 2018-01-07T11:00:00\n",
      "Provisional End: 2018-01-07T16:00:00\n",
      "Provisional Start: 2018-01-07T16:00:00\n",
      "Provisional End: 2018-01-07T21:00:00\n",
      "Provisional Start: 2018-01-07T21:00:00\n",
      "Provisional End: 2018-01-08T02:00:00\n",
      "Provisional Start: 2018-01-08T02:00:00\n",
      "Provisional End: 2018-01-08T07:00:00\n",
      "Provisional Start: 2018-01-08T07:00:00\n",
      "Provisional End: 2018-01-08T12:00:00\n",
      "Provisional Start: 2018-01-08T12:00:00\n",
      "Provisional End: 2018-01-08T17:00:00\n",
      "Provisional Start: 2018-01-08T17:00:00\n",
      "Provisional End: 2018-01-08T22:00:00\n",
      "Provisional Start: 2018-01-08T22:00:00\n",
      "Provisional End: 2018-01-09T03:00:00\n",
      "Provisional Start: 2018-01-09T03:00:00\n",
      "Provisional End: 2018-01-09T08:00:00\n",
      "Provisional Start: 2018-01-09T08:00:00\n",
      "Provisional End: 2018-01-09T13:00:00\n",
      "Provisional Start: 2018-01-09T13:00:00\n",
      "Provisional End: 2018-01-09T18:00:00\n",
      "Provisional Start: 2018-01-09T18:00:00\n",
      "Provisional End: 2018-01-09T23:00:00\n",
      "Provisional Start: 2018-01-09T23:00:00\n",
      "Provisional End: 2018-01-10T04:00:00\n",
      "Provisional Start: 2018-01-10T04:00:00\n",
      "Provisional End: 2018-01-10T09:00:00\n",
      "Provisional Start: 2018-01-10T09:00:00\n",
      "Provisional End: 2018-01-10T14:00:00\n",
      "Provisional Start: 2018-01-10T14:00:00\n",
      "Provisional End: 2018-01-10T19:00:00\n",
      "Provisional Start: 2018-01-10T19:00:00\n",
      "Provisional End: 2018-01-11T00:00:00\n",
      "Provisional Start: 2018-01-11T00:00:00\n",
      "Provisional End: 2018-01-11T05:00:00\n",
      "Provisional Start: 2018-01-11T05:00:00\n",
      "Provisional End: 2018-01-11T10:00:00\n",
      "Provisional Start: 2018-01-11T10:00:00\n",
      "Provisional End: 2018-01-11T15:00:00\n",
      "Provisional Start: 2018-01-11T15:00:00\n",
      "Provisional End: 2018-01-11T20:00:00\n",
      "Provisional Start: 2018-01-11T20:00:00\n",
      "Provisional End: 2018-01-12T01:00:00\n",
      "Provisional Start: 2018-01-12T01:00:00\n",
      "Provisional End: 2018-01-12T06:00:00\n",
      "Provisional Start: 2018-01-12T06:00:00\n",
      "Provisional End: 2018-01-12T11:00:00\n",
      "Provisional Start: 2018-01-12T11:00:00\n",
      "Provisional End: 2018-01-12T16:00:00\n",
      "Provisional Start: 2018-01-12T16:00:00\n",
      "Provisional End: 2018-01-12T21:00:00\n",
      "Provisional Start: 2018-01-12T21:00:00\n",
      "Provisional End: 2018-01-13T02:00:00\n",
      "Provisional Start: 2018-01-13T02:00:00\n",
      "Provisional End: 2018-01-13T07:00:00\n",
      "Provisional Start: 2018-01-13T07:00:00\n",
      "Provisional End: 2018-01-13T12:00:00\n",
      "Provisional Start: 2018-01-13T12:00:00\n",
      "Provisional End: 2018-01-13T17:00:00\n",
      "Provisional Start: 2018-01-13T17:00:00\n",
      "Provisional End: 2018-01-13T22:00:00\n",
      "Provisional Start: 2018-01-13T22:00:00\n",
      "Provisional End: 2018-01-14T03:00:00\n",
      "Provisional Start: 2018-01-14T03:00:00\n",
      "Provisional End: 2018-01-14T08:00:00\n",
      "Provisional Start: 2018-01-14T08:00:00\n",
      "Provisional End: 2018-01-14T13:00:00\n",
      "Provisional Start: 2018-01-14T13:00:00\n",
      "Provisional End: 2018-01-14T18:00:00\n",
      "Provisional Start: 2018-01-14T18:00:00\n",
      "Provisional End: 2018-01-14T23:00:00\n",
      "Provisional Start: 2018-01-14T23:00:00\n",
      "Provisional End: 2018-01-15T04:00:00\n",
      "Provisional Start: 2018-01-15T04:00:00\n",
      "Provisional End: 2018-01-15T09:00:00\n",
      "Provisional Start: 2018-01-15T09:00:00\n",
      "Provisional End: 2018-01-15T14:00:00\n",
      "Provisional Start: 2018-01-15T14:00:00\n",
      "Provisional End: 2018-01-15T19:00:00\n",
      "Provisional Start: 2018-01-15T19:00:00\n",
      "Provisional End: 2018-01-16T00:00:00\n",
      "Provisional Start: 2018-01-16T00:00:00\n",
      "Provisional End: 2018-01-16T05:00:00\n",
      "Provisional Start: 2018-01-16T05:00:00\n",
      "Provisional End: 2018-01-16T10:00:00\n",
      "Provisional Start: 2018-01-16T10:00:00\n",
      "Provisional End: 2018-01-16T15:00:00\n",
      "Provisional Start: 2018-01-16T15:00:00\n",
      "Provisional End: 2018-01-16T20:00:00\n",
      "Provisional Start: 2018-01-16T20:00:00\n",
      "Provisional End: 2018-01-17T01:00:00\n",
      "Provisional Start: 2018-01-17T01:00:00\n",
      "Provisional End: 2018-01-17T06:00:00\n",
      "Provisional Start: 2018-01-17T06:00:00\n",
      "Provisional End: 2018-01-17T11:00:00\n",
      "Provisional Start: 2018-01-17T11:00:00\n",
      "Provisional End: 2018-01-17T16:00:00\n",
      "Provisional Start: 2018-01-17T16:00:00\n",
      "Provisional End: 2018-01-17T21:00:00\n",
      "Provisional Start: 2018-01-17T21:00:00\n",
      "Provisional End: 2018-01-18T02:00:00\n",
      "Provisional Start: 2018-01-18T02:00:00\n",
      "Provisional End: 2018-01-18T07:00:00\n",
      "Provisional Start: 2018-01-18T07:00:00\n",
      "Provisional End: 2018-01-18T12:00:00\n",
      "Provisional Start: 2018-01-18T12:00:00\n",
      "Provisional End: 2018-01-18T17:00:00\n",
      "Provisional Start: 2018-01-18T17:00:00\n",
      "Provisional End: 2018-01-18T22:00:00\n",
      "Provisional Start: 2018-01-18T22:00:00\n",
      "Provisional End: 2018-01-19T03:00:00\n",
      "Provisional Start: 2018-01-19T03:00:00\n",
      "Provisional End: 2018-01-19T08:00:00\n",
      "Provisional Start: 2018-01-19T08:00:00\n",
      "Provisional End: 2018-01-19T13:00:00\n",
      "Provisional Start: 2018-01-19T13:00:00\n",
      "Provisional End: 2018-01-19T18:00:00\n",
      "Provisional Start: 2018-01-19T18:00:00\n",
      "Provisional End: 2018-01-19T23:00:00\n",
      "Provisional Start: 2018-01-19T23:00:00\n",
      "Provisional End: 2018-01-20T04:00:00\n",
      "Provisional Start: 2018-01-20T04:00:00\n",
      "Provisional End: 2018-01-20T09:00:00\n",
      "Provisional Start: 2018-01-20T09:00:00\n",
      "Provisional End: 2018-01-20T14:00:00\n",
      "Provisional Start: 2018-01-20T14:00:00\n",
      "Provisional End: 2018-01-20T19:00:00\n",
      "Provisional Start: 2018-01-20T19:00:00\n",
      "Provisional End: 2018-01-21T00:00:00\n",
      "Provisional Start: 2018-01-21T00:00:00\n",
      "Provisional End: 2018-01-21T05:00:00\n",
      "Provisional Start: 2018-01-21T05:00:00\n",
      "Provisional End: 2018-01-21T10:00:00\n",
      "Provisional Start: 2018-01-21T10:00:00\n",
      "Provisional End: 2018-01-21T15:00:00\n",
      "Provisional Start: 2018-01-21T15:00:00\n",
      "Provisional End: 2018-01-21T20:00:00\n",
      "Provisional Start: 2018-01-21T20:00:00\n",
      "Provisional End: 2018-01-22T01:00:00\n",
      "Provisional Start: 2018-01-22T01:00:00\n",
      "Provisional End: 2018-01-22T06:00:00\n",
      "Provisional Start: 2018-01-22T06:00:00\n",
      "Provisional End: 2018-01-22T11:00:00\n",
      "Provisional Start: 2018-01-22T11:00:00\n",
      "Provisional End: 2018-01-22T16:00:00\n",
      "Provisional Start: 2018-01-22T16:00:00\n",
      "Provisional End: 2018-01-22T21:00:00\n",
      "Provisional Start: 2018-01-22T21:00:00\n",
      "Provisional End: 2018-01-23T02:00:00\n",
      "Provisional Start: 2018-01-23T02:00:00\n",
      "Provisional End: 2018-01-23T07:00:00\n",
      "Provisional Start: 2018-01-23T07:00:00\n",
      "Provisional End: 2018-01-23T12:00:00\n",
      "Provisional Start: 2018-01-23T12:00:00\n",
      "Provisional End: 2018-01-23T17:00:00\n",
      "Provisional Start: 2018-01-23T17:00:00\n",
      "Provisional End: 2018-01-23T22:00:00\n",
      "Provisional Start: 2018-01-23T22:00:00\n",
      "Provisional End: 2018-01-24T03:00:00\n",
      "Provisional Start: 2018-01-24T03:00:00\n",
      "Provisional End: 2018-01-24T08:00:00\n",
      "Provisional Start: 2018-01-24T08:00:00\n",
      "Provisional End: 2018-01-24T13:00:00\n",
      "Provisional Start: 2018-01-24T13:00:00\n",
      "Provisional End: 2018-01-24T18:00:00\n",
      "Provisional Start: 2018-01-24T18:00:00\n",
      "Provisional End: 2018-01-24T23:00:00\n",
      "Provisional Start: 2018-01-24T23:00:00\n",
      "Provisional End: 2018-01-25T04:00:00\n",
      "Provisional Start: 2018-01-25T04:00:00\n",
      "Provisional End: 2018-01-25T09:00:00\n",
      "Provisional Start: 2018-01-25T09:00:00\n",
      "Provisional End: 2018-01-25T14:00:00\n",
      "Provisional Start: 2018-01-25T14:00:00\n",
      "Provisional End: 2018-01-25T19:00:00\n",
      "Provisional Start: 2018-01-25T19:00:00\n",
      "Provisional End: 2018-01-26T00:00:00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\VICTOR~1\\AppData\\Local\\Temp/ipykernel_12404/1938469579.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtrade_interval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m60\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Returns data as a dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m coinbase_data = HistoricalData(\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;34m'ETH-USD'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mtrade_interval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\Historic_Crypto\\HistoricalData.py\u001b[0m in \u001b[0;36mretrieve_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    175\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m                         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m                         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m                         print(\"\"\"CoinBase Pro API did not have available data for '{}' beginning at {}.  \n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Get CoinBase Data\n",
    "\"\"\"\n",
    "HistoricalData() info:\n",
    "| ticker | supply the ticker information which you want to return (str). | | granularity | please supply a granularity in seconds (60, 300, 900, 3600, 21600, 86400) (int). | | start_date | a string in the format YYYY-MM-DD-HH-MM (str). | | end_date | a string in the format YYYY-MM-DD-HH-MM (str). Optional, Default: Now | | verbose | printing during extraction. Default: True |\n",
    "\"\"\"\n",
    "# how many seconds between data points\n",
    "trade_interval = 60\n",
    "# Returns data as a dataframe\n",
    "coinbase_data = HistoricalData(\n",
    "    'ETH-USD',\n",
    "    trade_interval,\n",
    "    start_date='2018-01-01-00-00',\n",
    "    # end_date='2019-01-6-00-00', # Comment out to use current time as end\n",
    "    verbose=False\n",
    ").retrieve_data()\n",
    "\n",
    "# make time no longer the index and rename it\n",
    "coinbase_data.reset_index(inplace=True)\n",
    "coinbase_data.rename(columns = {'time':'timestamp'}, inplace = True)\n",
    "# Give the index a name for the csv\n",
    "coinbase_data.index.names = ['index']\n",
    "\n",
    "# turn timestamp from a datetime into a timestamp, divide by 10**9 to get seconds as our units\n",
    "coinbase_data['timestamp'] = coinbase_data['timestamp'].apply(lambda x: int(x.value// 10**9))\n",
    "# Create price data\n",
    "coinbase_data['decimal_price'] = round(coinbase_data['open'] + coinbase_data['close'] + coinbase_data['high'] + coinbase_data['low'], 4)\n",
    "# Then fractionalize the number to minimize floating point rounding errors\n",
    "coinbase_data['fraction_price'] = coinbase_data['decimal_price'].apply(lambda x: frac(x)/4)\n",
    "# Average out decimal price\n",
    "coinbase_data['decimal_price'] = coinbase_data['decimal_price']/4\n",
    "# drop all columns we don't want\n",
    "coinbase_data = coinbase_data.filter(['index', 'timestamp', 'fraction_price', 'decimal_price'])\n",
    "\n",
    "print(f'\\nSubset of data:\\n{coinbase_data.head(5)}')\n",
    "# Save data\n",
    "print(f'\\nHistorical values found: {len(coinbase_data.index)}')\n",
    "coinbase_data.to_csv(bs.full_path('CoinBase_ETH_all_price_data'))\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earliest timestamp found: 1502942400.0\n",
      "Human readable format: Wed Aug 16 21:00:00 2017\n",
      "Historical values found: 7201\n",
      "Subset of data:\n",
      "[[1546300800000, '131.45000000', '131.54000000', '131.42000000', '131.45000000', '240.20353000', 1546300859999, '31580.25136910', 87, '132.28472000', '17393.36952540', '0'], [1546300860000, '131.44000000', '131.44000000', '131.01000000', '131.22000000', '621.28854000', 1546300919999, '81529.91094440', 140, '262.86286000', '34508.77042620', '0'], [1546300920000, '131.22000000', '131.27000000', '131.19000000', '131.24000000', '64.85972000', 1546300979999, '8511.90702200', 38, '27.04020000', '3548.97590320', '0'], [1546300980000, '131.24000000', '131.30000000', '131.23000000', '131.28000000', '151.86484000', 1546301039999, '19932.27362780', 59, '119.30085000', '15658.01938440', '0'], [1546301040000, '131.27000000', '131.31000000', '131.24000000', '131.27000000', '190.91042000', 1546301099999, '25061.05237230', 80, '42.22663000', '5543.53532960', '0']]\n"
     ]
    }
   ],
   "source": [
    "# Get Binance Data\n",
    "\n",
    "# Initialise the client\n",
    "# NOTE: You will have to supply your OWN api keys to use this\n",
    "client = Client(api.get_api_key(), api.get_secret())\n",
    "# USDT has more historical price data than USDC\n",
    "trading_pair = 'ETHUSDT'\n",
    "# trading_pair = 'ETHUSDC'\n",
    "\n",
    "if trading_pair == 'ETHUSDT':\n",
    "    ## For ETH USDT\n",
    "    # Earliest timestamp found: 1502942400.0\n",
    "    # Human readable format: Wed Aug 16 21:00:00 2017\n",
    "    # However, early Binance ETH USDT data is not very good so only use 2018+ (aka 1514764800+)\n",
    "    # Multiply by 1000 to make what we would get from the query\n",
    "    timestamp = 1514764800*1000\n",
    "else:\n",
    "    # get timestamp of earliest date data is available\n",
    "    timestamp = client._get_earliest_valid_timestamp(trading_pair, AsyncClient.KLINE_INTERVAL_1MINUTE)\n",
    "    print(f'Earliest timestamp found: {int(timestamp)/1000}')\n",
    "    print(f'Human readable format: {time.ctime(int(timestamp)/1000)}')\n",
    "    ## For ETH USDC (not quite as much data as USDT)\n",
    "    # Earliest timestamp found: 1544844060.0\n",
    "    # Human readable format: Fri Dec 14 19:21:00 2018\n",
    "\n",
    "# query_start = '1 Jan, 2019'\n",
    "# query_end = '6 Jan, 2019'\n",
    "# # Get data between two specific times\n",
    "# klines = client.get_historical_klines(trading_pair, AsyncClient.KLINE_INTERVAL_1MINUTE, start_str=query_start, end_str=query_end)\n",
    "\n",
    "# Get data from the beginning of the Binance data to now\n",
    "klines = client.get_historical_klines(trading_pair, AsyncClient.KLINE_INTERVAL_1MINUTE, timestamp)\n",
    "\n",
    "print(f'Historical values found: {len(klines)}')\n",
    "print(f'Subset of data:\\n{klines[0:5]}')\n",
    "\n",
    "# save data as a file\n",
    "save_file_name = 'csv_files/Binance_ETH_all_price_data.csv'\n",
    "with open(save_file_name, 'w') as d:\n",
    "# with open('csv_files/ETH_all_price_data.csv', 'w') as d:\n",
    "    d.write('index,timestamp,fraction_price,decimal_price\\n')\n",
    "    # add index column\n",
    "    ind = 0\n",
    "    for line in klines:\n",
    "        fraction_price = frac(float(line[1])+float(line[2])+float(line[3])+float(line[4]))/4\n",
    "        decimal_price = round(fraction_price, 4)\n",
    "        # Divide timestamp by 1000 so we can remove three 000s from the timestamp.\n",
    "        # This makes the timestamp units seconds which matches the other data we have.\n",
    "        d.write(f'{ind},{int(int(line[0])/1000)},{fraction_price},{decimal_price}\\n')\n",
    "        # keep track of index\n",
    "        ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if csv are sorted\n",
    "for csv in list_of_csv:\n",
    "    data = pd.read_csv(bs.full_path(csv))\n",
    "    sorted_data = data.sort_values(by=['timestamp'])\n",
    "    print(f'{csv} is sorted?: {data.equals(sorted_data)}')\n",
    "    # The above resulted in \n",
    "    # full_data__6__2018.csv is sorted?: True\n",
    "    # full_data__6__2019.csv is sorted?: False\n",
    "    # full_data__6__2020.csv is sorted?: False\n",
    "    # full_data__6__2021.csv is sorted?: False\n",
    "    # So we have to sort the data (only do this once)\n",
    "    \n",
    "    # Test for nulls\n",
    "    null_counts = sorted_data[['timestamp', 'Open', 'Close', 'High', 'Low']].isnull().sum()\n",
    "    null_counts[null_counts > 0].sort_values(ascending=False)\n",
    "    print('Null values found:')\n",
    "    print(null_counts)\n",
    "    # No nulls!\n",
    "\n",
    "    # Create 'price' column from avg of Open and Close\n",
    "    # First make the row and round to 4 decimals\n",
    "    # Divide by 4 after we make the fraction_price\n",
    "    sorted_data['decimal_price'] = round(sorted_data['Open'] + sorted_data['Close'] + sorted_data['High'] + sorted_data['Low'],\n",
    "         4)\n",
    "    # Then fractionalize the number to minimize floating point rounding errors\n",
    "    sorted_data['fraction_price'] = sorted_data['decimal_price'].apply(lambda x: frac(x)/4)\n",
    "    # Average out decimal price\n",
    "    sorted_data['decimal_price'] = sorted_data['decimal_price']/4\n",
    "    # Give the index a name for the csv\n",
    "    sorted_data.index.names = ['index']\n",
    "    # drop all columns we don't want\n",
    "    sorted_data = sorted_data.filter(['index', 'timestamp', 'fraction_price', 'decimal_price'])\n",
    "    # Only run this once\n",
    "    # NOTE: Uncomment this when running for the first time\n",
    "    sorted_data.to_csv(bs.full_path('sorted_full_data_'+ csv[-8:]))\n",
    "\n",
    "# Spacing\n",
    "print('\\nSorted check:')\n",
    "# Show that sorted data is sorted\n",
    "for csv in sorted_list_of_csv:\n",
    "    data = pd.read_csv(bs.full_path(csv))\n",
    "    sorted_data = data.sort_values(by=['timestamp'])\n",
    "    print(f'{csv} is sorted?: {data.equals(sorted_data)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine ALL data into one big file\n",
    "\n",
    "# initialize list of all of the files we want to look at\n",
    "overall_list = [\n",
    "    'Binance_ETH_all_price_data.csv',\n",
    "    'CoinBase_ETH_all_price_data.csv'\n",
    "]\n",
    "# add the Kaggle data to our list\n",
    "overall_list = overall_list + sorted_list_of_csv\n",
    "\n",
    "# initialize empty dataframe to hold all the values\n",
    "combined_df = pd.DataFrame(columns=['timestamp', 'fraction_price', 'decimal_price'])\n",
    "\n",
    "# combine all the data into one dataset\n",
    "for csv in overall_list:\n",
    "    print(f'Adding {csv}')\n",
    "    new_data = pd.read_csv(bs.full_path(csv))\n",
    "    combined_df = idh.combine_datasets(combined_df, new_data)\n",
    "\n",
    "# Drop the fake index\n",
    "combined_df = combined_df.drop(columns=['index'])\n",
    "# Name the real index for the csv\n",
    "combined_df.index.names = ['index']\n",
    "\n",
    "# save result to a file\n",
    "combined_df.to_csv('csv_files/Combined_ETH_all_price_data.csv')\n",
    "print('Results Saved!\\n')\n",
    "\n",
    "# Check if we have any timestamp gaps in our data\n",
    "# Ideally we would only see the final timestamp printed\n",
    "idh.check_missing_timestamp(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idh.create_price_period('1/1/2018','1/5/2018', 'test')\n",
    "# idh.create_price_period('1/1/2018','2/1/2018', 'test_month')\n",
    "\n",
    "# --- Specific price_periods --- \n",
    "# Yearly\n",
    "idh.create_price_period('1/1/2018','1/1/2019', '2018_price_data')\n",
    "idh.create_price_period('1/1/2019','1/1/2020', '2019_price_data')\n",
    "idh.create_price_period('1/1/2020','1/1/2021', '2020_price_data')\n",
    "idh.create_price_period('1/1/2021','1/1/2022', '2021_price_data') \n",
    "# Past 4 Years - 2018 through 2021\n",
    "idh.create_price_period('1/1/2018', '1/1/2022', '2018-2021')\n",
    "# Past 3 Years - 2019 through 2021\n",
    "idh.create_price_period('1/1/2019', '1/1/2022', '2019-2021')\n",
    "# Past 2 Years - 2020 through 2021\n",
    "idh.create_price_period('1/1/2020', '1/1/2022', '2020-2021')\n",
    "# Past 1 Year - all of 2021 # Low to high to low to high\n",
    "idh.create_price_period('1/1/2021', '1/1/2022', '2021')\n",
    "\n",
    "# High to low \n",
    "# - 1515870180 (max of 2018) to end of 2018\n",
    "idh.create_price_period(1515870180, 1546300740, 'High-Low-1')\n",
    "# - 1620125000 (before 2021 crash) to 1627000000 (2021 crash low)\n",
    "idh.create_price_period(1620125000, 1627000000, 'High-Low-2')\n",
    "\n",
    "# Low to high \n",
    "# - start of 2020 to 1620125000 (before 2021 crash)\n",
    "idh.create_price_period('1/1/2020', 1620125000, 'Low-High-1')\n",
    "# - 1627000000 (2021 crash low) to end of 2021\n",
    "idh.create_price_period(1627000000, '1/1/2022', 'Low-High-2')\n",
    "\n",
    "# Low to high to low\n",
    "# - all of 2019\n",
    "idh.create_price_period('1/1/2019', 1577836740, 'Low-High-Low-1')\n",
    "# - 2021 start to 1627000000 (2021 crash low)\n",
    "idh.create_price_period('1/1/2021', 1627000000, 'Low-High-Low-2')\n",
    "\n",
    "# High to low to high\n",
    "# - 1515870180 (2018) to 1620125000 (before 2021 crash)\n",
    "idh.create_price_period(1515870180, 1620125000, 'High-Low-High-1')\n",
    "# - 1620125000 (before 2021 crash) to end of 2021\n",
    "idh.create_price_period(1620125000, '1/1/2022', 'High-Low-High-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recalibrate time variable in a new row to start at 0\n",
    "# start_time = data['Time'].values[0]\n",
    "# data['Cal Time'] = data['Time'].apply(lambda x: x - start_time)\n",
    "\n",
    "# Examples\n",
    "# Plot data returned\n",
    "# By default x=index\n",
    "# data.plot(y='Price', kind='line')\n",
    "# data.plot(x='Cal Time', y=['Price', 'Plus .3%', 'Minus .3%'], kind='line')\n",
    "# data.plot(x='Cal Time', y=['Price', 'Plus .3%', 'Minus .3%'], kind='line', xlim=(35000,45000))\n",
    "# data.plot(x='Cal Time', y=['Price', 'Plus .3%', 'Minus .3%'], kind='line', ylim=(data['Price'].mean()*(1-.005),data['Price'].mean()*(1+.005)))\n",
    "\n",
    "# testing\n",
    "data = pd.read_csv(get_test_data_path('test.csv'), index_col='index')\n",
    "# print(type(data['fraction_price'].values[0]))\n",
    "# print(dir(data['price'].values[0]))\n",
    "start_datetime = pd.to_datetime(data['timestamp'].iloc[0], unit='s')\n",
    "end_datetime = pd.to_datetime(data['timestamp'].iloc[-1], unit='s')\n",
    "print(f'Start datetime: {start_datetime}')\n",
    "print(f'End datetime:   {end_datetime}')\n",
    "data.plot(x='timestamp', y='decimal_price', kind='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yearly Price Plots\n",
    "for csv in sorted_list_of_csv:\n",
    "    data = pd.read_csv(bs.full_path(csv), index_col='index')\n",
    "    start_datetime = pd.to_datetime(data['timestamp'].iloc[0], unit='s')\n",
    "    end_datetime = pd.to_datetime(data['timestamp'].iloc[-1], unit='s')\n",
    "    print(f'Start datetime: {start_datetime}')\n",
    "    print(f'End datetime:   {end_datetime}')\n",
    "    data.plot(x='timestamp', y='decimal_price', title=csv, kind='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = 'Combined_ETH_all_price_data.csv'\n",
    "print(csv)\n",
    "data = pd.read_csv(bs.full_path(csv), index_col='index')\n",
    "start_datetime = pd.to_datetime(data['timestamp'].iloc[0], unit='s')\n",
    "end_datetime = pd.to_datetime(data['timestamp'].iloc[-1], unit='s')\n",
    "print(f'Start datetime: {start_datetime}')\n",
    "print(f'End datetime:   {end_datetime}')\n",
    "data.plot(x='timestamp', y='decimal_price', title=csv, kind='line')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7f6ce40941103abb3416a795e028450c6c1ee6bd4c25de01325501f9db33dc9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
